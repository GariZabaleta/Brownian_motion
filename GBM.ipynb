{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPh5xMd+LChwiDnu49YgRcj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Literature\n",
        "\n",
        "https://quantpy.com.au/stochastic-calculus/brownian-motion-for-financial-mathematics/\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=sIKD1tQryHg\n",
        "\n",
        "https://www.quantstart.com/articles/geometric-brownian-motion-simulation-with-python/\n",
        "\n",
        "https://towardsdatascience.com/stochastic-processes-simulation-brownian-motion-the-basics-c1d71585d9f9\n",
        "\n",
        "\n",
        "https://github.com/GariZabaleta/jpx-tokyo-stock-exchange-prediction/blob/master/jpx-prediction.ipynb\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/5-amazing-pandas-features-you-probably-dont-know-about-5533498aac88\n",
        "\n",
        "\n",
        "**Calculating log values**\n",
        "\n",
        "https://stackoverflow.com/questions/31742545/python-calculating-log-returns-of-a-time-series\n"
      ],
      "metadata": {
        "id": "y26RdeHhOrdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Import libraries\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KPSn7PvKLQWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import string"
      ],
      "metadata": {
        "id": "JM7FZRO7OsWb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import neighbors\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error"
      ],
      "metadata": {
        "id": "PYaf7yrfLSxv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots"
      ],
      "metadata": {
        "id": "HHCKJcuhabu-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Geometric Brownian motion\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TDXxYN0483EV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeometricBrownianMotionAssetSimulator:\n",
        "    \"\"\"\n",
        "    This callable class will generate a daily\n",
        "    close price based DataFrame to simulate\n",
        "    asset pricing paths with Geometric Brownian Motion for pricing\n",
        "\n",
        "    For now the tool is hardcoded to generate business day daily\n",
        "    data between two dates, inclusive.\n",
        "\n",
        "    Note that the pricing data is completely uncorrelated,\n",
        "    which is not likely to be the case in real asset paths.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    start_date : `str`\n",
        "        The starting date in YYYY-MM-DD format.\n",
        "    end_date : `str`\n",
        "        The ending date in YYYY-MM-DD format.\n",
        "    init_price : `float`\n",
        "        The initial price of the asset.\n",
        "    mu : `float`\n",
        "        The mean 'drift' of the asset.\n",
        "    sigma : `float`\n",
        "        The 'volatility' of the asset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_date,\n",
        "        end_date,\n",
        "        init_price,\n",
        "        mu,\n",
        "        sigma,\n",
        "    ):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.init_price = init_price\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def _generate_random_symbol(self):\n",
        "        \"\"\"\n",
        "        Generates a random ticker symbol string composed of\n",
        "        uppercase ASCII characters\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `str`\n",
        "            The random ticker string composed of uppercase letters.\n",
        "        \"\"\"\n",
        "        return ''.join(\n",
        "            random.choices(\n",
        "                string.ascii_uppercase,\n",
        "                k=4\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def _create_empty_frame(self,symbol):\n",
        "        \"\"\"\n",
        "        Creates the empty Pandas DataFrame with a date column using\n",
        "        business days between two dates. Each of the price\n",
        "        columns are set to zero.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            The empty  DataFrame for subsequent population.\n",
        "        \"\"\"\n",
        "        date_range = pd.date_range(\n",
        "            self.start_date,\n",
        "            self.end_date,\n",
        "            freq='B'\n",
        "        )\n",
        "\n",
        "        zeros = pd.Series(np.zeros(len(date_range)))\n",
        "\n",
        "        return pd.DataFrame(\n",
        "            {\n",
        "                'date': date_range,\n",
        "                symbol: zeros\n",
        "            }\n",
        "        )[['date', symbol]]\n",
        "\n",
        "    def _create_geometric_brownian_motion(self, data):\n",
        "        \"\"\"\n",
        "        Calculates an asset price path using the analytical solution\n",
        "        to the Geometric Brownian Motion stochastic differential\n",
        "        equation (SDE).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : `pd.DataFrame`\n",
        "            The DataFrame needed to calculate length of the time series.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `np.ndarray`\n",
        "            The asset price path \n",
        "        \"\"\"\n",
        "        n = len(data)\n",
        "        T = n / 252.0  # Business days in a year\n",
        "        dt = T / n \n",
        "        \n",
        "        # Vectorised implementation of asset path generation\n",
        "        asset_path = np.exp(\n",
        "            (self.mu - self.sigma**2 / 2) * dt +\n",
        "            self.sigma * np.random.normal(0, np.sqrt(dt), size= n )\n",
        "        )\n",
        "        \n",
        "        return self.init_price * asset_path.cumprod()\n",
        "\n",
        "    def _append_path_to_data(self, data, path,symbol):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : `pd.DataFrame`\n",
        "            The price/volume DataFrame to modify in place.\n",
        "        path : `np.ndarray`\n",
        "            The original NumPy array of the asset price path.\n",
        "        \"\"\"\n",
        "        data[symbol] = path\n",
        "\n",
        "\n",
        "    def __call__(self):\n",
        "        \"\"\"\n",
        "        The entrypoint for generating the asset  frame. Firstly this\n",
        "        generates a symbol and an empty frame. It then populates this\n",
        "        frame with some simulated GBM data.\n",
        "        \"\"\"\n",
        "        symbol = self._generate_random_symbol()\n",
        "        data = self._create_empty_frame()\n",
        "        path = self._create_geometric_brownian_motion(data)\n",
        "        self._append_path_to_data(data, path)\n",
        "\n",
        "\n",
        "def gen(random_seed, start_date, end_date, init_price, mu, sigma):\n",
        "    random_seed = int(random_seed)\n",
        "    init_price = float(init_price)\n",
        "    mu = float(mu)\n",
        "    sigma = float(sigma)\n",
        "\n",
        "    # Need to seed both Python and NumPy separately\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(seed=random_seed)\n",
        "\n",
        "    gbmas = GeometricBrownianMotionAssetSimulator(\n",
        "        start_date,\n",
        "        end_date,\n",
        "        init_price,\n",
        "        mu,\n",
        "        sigma,\n",
        "    )\n",
        "    return gbmas\n",
        "     "
      ],
      "metadata": {
        "id": "I13WHURmDw_6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_data = \"2017-01-01\"\n",
        "end_data = \"2022-12-31\""
      ],
      "metadata": {
        "id": "KYsycvhozg_t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = []\n",
        "for i in range(0,10):\n",
        "  stock = gen(i, start_data, end_data,100,0.1,0.2)\n",
        "\n",
        "  symbol = stock._generate_random_symbol()        \n",
        "  data = stock._create_empty_frame(symbol)\n",
        "  path = stock._create_geometric_brownian_motion(data)\n",
        "  stock._append_path_to_data(data, path,symbol)\n",
        "\n",
        "  if i == 0:\n",
        "    df = data.copy()\n",
        "  else:\n",
        "    df = pd.concat([df,data[symbol]], axis = 1)\n",
        "\n",
        "df = df.set_index(\"date\")"
      ],
      "metadata": {
        "id": "wk0nJvY80JGU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "d26QM5Co0JQW",
        "outputId": "9271f286-91b5-4d7f-f524-e74ceb0fa2df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  VTKG        DWTG       YYBC        GOJP        GCKE  \\\n",
              "date                                                                    \n",
              "2017-01-02  102.279843  102.099974  99.507895  102.311517  100.095493   \n",
              "2017-01-03  102.829429  101.348242  99.468952  102.908394  100.759946   \n",
              "2017-01-04  104.138317  100.708041  96.858338  103.066296   99.535176   \n",
              "2017-01-05  107.154321   99.387363  98.912182  100.706675  100.440658   \n",
              "2017-01-06  109.740285  100.508826  96.733009  100.387208   99.944441   \n",
              "...                ...         ...        ...         ...         ...   \n",
              "2022-12-26  118.253672  409.506673  62.465585  123.907478  309.864934   \n",
              "2022-12-27  117.336427  416.939245  61.453604  125.391893  310.478921   \n",
              "2022-12-28  115.709274  419.380784  61.257502  124.465044  310.604221   \n",
              "2022-12-29  117.208715  417.294179  60.757400  124.237516  318.523192   \n",
              "2022-12-30  117.026385  422.775341  60.583527  124.476520  323.452046   \n",
              "\n",
              "                  QTUY        UVMG        IDQB        FZDS        MJDW  \n",
              "date                                                                    \n",
              "2017-01-02  100.589370   99.639587  102.185140  100.146761  100.033148  \n",
              "2017-01-03  100.202734  100.590879  101.619299  101.565412   99.700547  \n",
              "2017-01-04  103.351704  100.899335  101.693605   99.135836   98.339670  \n",
              "2017-01-05  103.056685   99.794523  102.249521   97.450259   98.354929  \n",
              "2017-01-06  103.231867   96.747091  101.270390   94.701181   97.918276  \n",
              "...                ...         ...         ...         ...         ...  \n",
              "2022-12-26  251.497558  175.216423   97.153936  426.964560  198.490468  \n",
              "2022-12-27  251.547898  172.461570   97.638068  420.536009  197.122543  \n",
              "2022-12-28  255.211306  175.626566   96.002537  422.663860  201.764408  \n",
              "2022-12-29  250.791698  175.343510   98.653878  429.754767  201.659396  \n",
              "2022-12-30  245.967662  177.901520   98.822888  430.773990  201.048648  \n",
              "\n",
              "[1565 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5caed5a9-bf2c-4c35-a095-107dcf17f006\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VTKG</th>\n",
              "      <th>DWTG</th>\n",
              "      <th>YYBC</th>\n",
              "      <th>GOJP</th>\n",
              "      <th>GCKE</th>\n",
              "      <th>QTUY</th>\n",
              "      <th>UVMG</th>\n",
              "      <th>IDQB</th>\n",
              "      <th>FZDS</th>\n",
              "      <th>MJDW</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-02</th>\n",
              "      <td>102.279843</td>\n",
              "      <td>102.099974</td>\n",
              "      <td>99.507895</td>\n",
              "      <td>102.311517</td>\n",
              "      <td>100.095493</td>\n",
              "      <td>100.589370</td>\n",
              "      <td>99.639587</td>\n",
              "      <td>102.185140</td>\n",
              "      <td>100.146761</td>\n",
              "      <td>100.033148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>102.829429</td>\n",
              "      <td>101.348242</td>\n",
              "      <td>99.468952</td>\n",
              "      <td>102.908394</td>\n",
              "      <td>100.759946</td>\n",
              "      <td>100.202734</td>\n",
              "      <td>100.590879</td>\n",
              "      <td>101.619299</td>\n",
              "      <td>101.565412</td>\n",
              "      <td>99.700547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>104.138317</td>\n",
              "      <td>100.708041</td>\n",
              "      <td>96.858338</td>\n",
              "      <td>103.066296</td>\n",
              "      <td>99.535176</td>\n",
              "      <td>103.351704</td>\n",
              "      <td>100.899335</td>\n",
              "      <td>101.693605</td>\n",
              "      <td>99.135836</td>\n",
              "      <td>98.339670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>107.154321</td>\n",
              "      <td>99.387363</td>\n",
              "      <td>98.912182</td>\n",
              "      <td>100.706675</td>\n",
              "      <td>100.440658</td>\n",
              "      <td>103.056685</td>\n",
              "      <td>99.794523</td>\n",
              "      <td>102.249521</td>\n",
              "      <td>97.450259</td>\n",
              "      <td>98.354929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-06</th>\n",
              "      <td>109.740285</td>\n",
              "      <td>100.508826</td>\n",
              "      <td>96.733009</td>\n",
              "      <td>100.387208</td>\n",
              "      <td>99.944441</td>\n",
              "      <td>103.231867</td>\n",
              "      <td>96.747091</td>\n",
              "      <td>101.270390</td>\n",
              "      <td>94.701181</td>\n",
              "      <td>97.918276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-26</th>\n",
              "      <td>118.253672</td>\n",
              "      <td>409.506673</td>\n",
              "      <td>62.465585</td>\n",
              "      <td>123.907478</td>\n",
              "      <td>309.864934</td>\n",
              "      <td>251.497558</td>\n",
              "      <td>175.216423</td>\n",
              "      <td>97.153936</td>\n",
              "      <td>426.964560</td>\n",
              "      <td>198.490468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>117.336427</td>\n",
              "      <td>416.939245</td>\n",
              "      <td>61.453604</td>\n",
              "      <td>125.391893</td>\n",
              "      <td>310.478921</td>\n",
              "      <td>251.547898</td>\n",
              "      <td>172.461570</td>\n",
              "      <td>97.638068</td>\n",
              "      <td>420.536009</td>\n",
              "      <td>197.122543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>115.709274</td>\n",
              "      <td>419.380784</td>\n",
              "      <td>61.257502</td>\n",
              "      <td>124.465044</td>\n",
              "      <td>310.604221</td>\n",
              "      <td>255.211306</td>\n",
              "      <td>175.626566</td>\n",
              "      <td>96.002537</td>\n",
              "      <td>422.663860</td>\n",
              "      <td>201.764408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>117.208715</td>\n",
              "      <td>417.294179</td>\n",
              "      <td>60.757400</td>\n",
              "      <td>124.237516</td>\n",
              "      <td>318.523192</td>\n",
              "      <td>250.791698</td>\n",
              "      <td>175.343510</td>\n",
              "      <td>98.653878</td>\n",
              "      <td>429.754767</td>\n",
              "      <td>201.659396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>117.026385</td>\n",
              "      <td>422.775341</td>\n",
              "      <td>60.583527</td>\n",
              "      <td>124.476520</td>\n",
              "      <td>323.452046</td>\n",
              "      <td>245.967662</td>\n",
              "      <td>177.901520</td>\n",
              "      <td>98.822888</td>\n",
              "      <td>430.773990</td>\n",
              "      <td>201.048648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1565 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5caed5a9-bf2c-4c35-a095-107dcf17f006')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5caed5a9-bf2c-4c35-a095-107dcf17f006 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5caed5a9-bf2c-4c35-a095-107dcf17f006');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = random.randint(0,10)\n",
        "\n",
        "X_train = df.iloc[:-5,:].copy()\n",
        "X_train.drop(X_train.columns[n], axis=1, inplace = True)\n",
        "y_train = df.iloc[:-5,n].copy()\n",
        "\n",
        "X_test = df.iloc[-5:,:].copy()\n",
        "X_test.drop(X_test.columns[n], axis=1, inplace = True)\n",
        "y_test = df.iloc[-5:,n].copy()\n"
      ],
      "metadata": {
        "id": "H0szWkjPNLFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Train**"
      ],
      "metadata": {
        "id": "pSOhUGBeQ4rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---X_train----\")\n",
        "display(X_train)\n",
        "print(\"\\n--y_train----\")\n",
        "display(y_train)"
      ],
      "metadata": {
        "id": "kxBO07rnQ2zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Test**"
      ],
      "metadata": {
        "id": "ceVBOFTORgV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---X_test----\")\n",
        "display(X_test)\n",
        "print(\"\\n--y_test----\")\n",
        "display(y_test)"
      ],
      "metadata": {
        "id": "nwMAfVy3RdDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G7vzIXW3QN30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_mat = np.abs(X_train.corr())\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.heatmap(corr_mat,square = True, ax = ax)"
      ],
      "metadata": {
        "id": "iv_ltdT1DZuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "period = [3,5,10,21]\n",
        "col = X_train.columns\n",
        "for j in col:\n",
        "  for i in period:\n",
        "    X_train[f\"pct_{j}_{i}\"] = X_train[j].pct_change(i)\n",
        "    X_train[f\"pct_{j}_{i}\"] = X_train[f\"pct_{j}_{i}\"].interpolate(method='linear',limit_direction='backward')\n",
        "\n",
        "    X_train[f\"Volatility_{j}_{i}\"] = np.log(X_train[j]).diff().rolling(i).std()\n",
        "    X_train[f\"Volatility_{j}_{i}\"] = X_train[f\"Volatility_{j}_{i}\"].interpolate(method='linear',limit_direction='backward')"
      ],
      "metadata": {
        "id": "bnXnRzOjI2tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "GPggaewXQeEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.drop(col, axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "uY4M4dIfQew_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "fBzBTa_uQGQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.histplot(data=X_train[\"pct_IDQB_10\"].values, bins=100,\n",
        "             ax=ax)\n",
        "ax.axvline(x=X_train[\"pct_IDQB_10\"].mean(), color='red', linestyle='dotted', linewidth=2, \n",
        "           label='Mean')\n",
        "\n",
        "ax.set_title(\"Target Mean Distibution Date\\n\"\n",
        "             f\"\"\"Min {round(X_train[\"pct_IDQB_10\"].min(), 4)} | \"\"\"\n",
        "             f\"\"\"Max {round(X_train[\"pct_IDQB_10\"].max(), 4)} | \"\"\"\n",
        "             f\"\"\"Skewness {round(X_train[\"pct_IDQB_10\"].skew(), 2)} | \"\"\"\n",
        "             f\"\"\"Kurtosis {round(X_train[\"pct_IDQB_10\"].kurtosis(), 2)}\"\"\")\n",
        "\n",
        "ax.set_xlabel(\"Target Mean\")\n",
        "ax.set_ylabel(\"Date Count\")\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LZmehKCa8bJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model selection\n",
        "\n",
        "- K-Nearest Neighbour Regressor\n",
        "- Decision tree\n",
        "- Random Forest\n"
      ],
      "metadata": {
        "id": "5BiWYJVlRkTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_dict = {\"KNN\":[],\"Decision_Tree\":[],\"Random_Forest\":[]}"
      ],
      "metadata": {
        "id": "OUFS_YNuc-_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Nearest Neighbour Regressor**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OTqRGEdnT3-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_fold = TimeSeriesSplit(n_splits=5,gap=10)\n",
        "mae_ls = []"
      ],
      "metadata": {
        "id": "IvX16raoUAPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for fold, (train_idx, val_idx) in enumerate(ts_fold.split(X_train, y_train)):\n",
        "    \n",
        "    print(f\"\\n========================== Fold {fold+1} ==========================\")\n",
        "        \n",
        "    X_train_cross, y_train_cross = X_train.iloc[train_idx,:], y_train[train_idx]\n",
        "    X_valid, y_val = X_train.iloc[val_idx,:], y_train[val_idx]\n",
        "    \n",
        "    print(\"Train Date range: {} to {}\".format(X_train_cross.index.min(),X_train_cross.index.max()))\n",
        "    print(\"Valid Date range: {} to {}\".format(X_valid.index.min(),X_valid.index.max()))\n",
        "\n",
        "    n_neighbors = 3\n",
        "    knn_reg = neighbors.KNeighborsRegressor(n_neighbors)\n",
        "    knn_reg.fit(X_train_cross, y_train_cross)\n",
        "    y_pred = knn_reg.predict(X_valid)\n",
        "\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "    print(f\"\\nMAE: {round(mae,2)}\")\n",
        "    mae_ls.append(mae)\n",
        "\n",
        "\n",
        "print(f\"\\nMean MAE {round(sum(mae_ls)/len(mae_ls),2)}\")\n",
        "mae_dict[\"KNN\"].append(round(sum(mae_ls)/len(mae_ls),2))"
      ],
      "metadata": {
        "id": "72NRElJiUARg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree** \n",
        "\n"
      ],
      "metadata": {
        "id": "oTmwUgmdT4Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_fold = TimeSeriesSplit(n_splits=5,gap=10)\n",
        "mae_ls = []"
      ],
      "metadata": {
        "id": "JYId9j_zUA5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for fold, (train_idx, val_idx) in enumerate(ts_fold.split(X_train, y_train)):\n",
        "    \n",
        "    print(f\"\\n========================== Fold {fold+1} ==========================\")\n",
        "        \n",
        "    X_train_cross, y_train_cross = X_train.iloc[train_idx,:], y_train[train_idx]\n",
        "    X_valid, y_val = X_train.iloc[val_idx,:], y_train[val_idx]\n",
        "    \n",
        "    print(\"Train Date range: {} to {}\".format(X_train_cross.index.min(),X_train_cross.index.max()))\n",
        "    print(\"Valid Date range: {} to {}\".format(X_valid.index.min(),X_valid.index.max()))\n",
        "\n",
        "    tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "    tree_reg.fit(X_train_cross, y_train_cross)\n",
        "    y_pred = tree_reg.predict(X_valid)\n",
        "\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "    print(f\"\\nMAE: {round(mae,2)}\")\n",
        "    mae_ls.append(mae)\n",
        "\n",
        "\n",
        "print(f\"\\nMean MAE {round(sum(mae_ls)/len(mae_ls),2)}\")\n",
        "mae_dict[\"Decision_Tree\"].append(round(sum(mae_ls)/len(mae_ls),2))"
      ],
      "metadata": {
        "id": "1XaWAaiiXiIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "7Yd9RuBnS7wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_fold = TimeSeriesSplit(n_splits=5,gap=10)\n",
        "feat_importance_forest = pd.DataFrame()\n",
        "mae_ls = []"
      ],
      "metadata": {
        "id": "KQ-QwEoTRS0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for fold, (train_idx, val_idx) in enumerate(ts_fold.split(X_train, y_train)):\n",
        "    \n",
        "    print(f\"\\n========================== Fold {fold+1} ==========================\")\n",
        "        \n",
        "    X_train_cross, y_train_cross = X_train.iloc[train_idx,:], y_train[train_idx]\n",
        "    X_valid, y_val = X_train.iloc[val_idx,:], y_train[val_idx]\n",
        "    \n",
        "    print(\"Train Date range: {} to {}\".format(X_train_cross.index.min(),X_train_cross.index.max()))\n",
        "    print(\"Valid Date range: {} to {}\".format(X_valid.index.min(),X_valid.index.max()))\n",
        "\n",
        "    regr = RandomForestRegressor()\n",
        "    regr.fit(X_train_cross, y_train_cross)\n",
        "    y_pred = regr.predict(X_valid)\n",
        "\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "    print(f\"\\nMAE: {round(mae,2)}\")\n",
        "    mae_ls.append(mae)\n",
        "\n",
        "\n",
        "print(f\"\\nMean MAE {round(sum(mae_ls)/len(mae_ls),2)}\")\n",
        "mae_dict[\"Random_Forest\"].append(round(sum(mae_ls)/len(mae_ls),2))"
      ],
      "metadata": {
        "id": "oW1jHCzeR0Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting the best model**"
      ],
      "metadata": {
        "id": "1yCf1QM6iYak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mae_dict)"
      ],
      "metadata": {
        "id": "vGrlkEAIiWCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Random Forest model provides a better MAE, it will be used to build the final model"
      ],
      "metadata": {
        "id": "odTYyMJbjOqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "metadata": {
        "id": "3yRfSeCrD9vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_fold = TimeSeriesSplit(n_splits=5,gap=10)\n",
        "regr_final = RandomForestRegressor()\n",
        "\n",
        "gsearch = GridSearchCV(estimator=regr_final, cv=ts_fold,\n",
        "                       scoring = 'neg_mean_absolute_percentage_error',\n",
        "                      param_grid=random_grid)\n",
        "gsearch.fit(X_train, y_train)\n",
        "results = gsearch.cv_results_"
      ],
      "metadata": {
        "id": "m8CvPoa7iWLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "p2FsCZNd_L80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model"
      ],
      "metadata": {
        "id": "Ni3XuyVWeCt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = gsearch.best_estimator_\n",
        "final_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OYPREoA_cS7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "period = [3,5,10,21]\n",
        "col = X_test.columns\n",
        "for j in col:\n",
        "  for i in period:\n",
        "    X_test[f\"pct_{j}_{i}\"] = X_test[j].pct_change(i)\n",
        "    X_test[f\"pct_{j}_{i}\"] = X_test[f\"pct_{j}_{i}\"].interpolate(method='linear',limit_direction='backward')\n",
        "\n",
        "    X_test[f\"Volatility_{j}_{i}\"] = np.log(X_test[j]).diff().rolling(i).std()\n",
        "    X_test[f\"Volatility_{j}_{i}\"] = X_test[f\"Volatility_{j}_{i}\"].interpolate(method='linear',limit_direction='backward')"
      ],
      "metadata": {
        "id": "nh-98_F-ggx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_final_pred = regr.predict(X_test)\n",
        "final_mae = mean_absolute_error(y_test, y_final_pred)\n"
      ],
      "metadata": {
        "id": "OlvW7sYqTTSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_mae"
      ],
      "metadata": {
        "id": "U5LAShfgTTVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ka6bycBJTTYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}